{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFxcPZInKxPV",
        "colab_type": "text"
      },
      "source": [
        "Short Summary at https://docs.google.com/document/d/1-FUR143YcUYACe57fZ7yAZrDTEbvD8u5XsjVoHu2XQE/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLfI8r0eadYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend, datasets, optimizers, regularizers, utils\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, Activation, Lambda, Add, \n",
        "BatchNormalization, Dense, GlobalAveragePooling2D, Dropout)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6M7gp0oGGwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backend.set_image_data_format('channels_last')\n",
        "l=1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNQPx8XeaxPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(Model):\n",
        "  \"\"\" Basic Block with identity mapping in shortcuts (Option A).\"\"\"\n",
        "  def __init__(self, out_channels, stride=(1,1)):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(out_channels, 3, strides=stride, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.relu1 = Activation('relu')\n",
        "    self.conv2 = Conv2D(out_channels, 3, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn2 = BatchNormalization()\n",
        "    if stride[0] != 1:\n",
        "      self.shortcut = Conv2D(out_channels, 1, strides=2, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    else:\n",
        "      self.shortcut = Lambda(lambda x: x)\n",
        "    self.bn3 = BatchNormalization()\n",
        "    self.add = Add()\n",
        "    self.relu2 = Activation('relu')\n",
        "\n",
        "  def call(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.bn1(y)\n",
        "    y = self.relu1(y)\n",
        "    y = self.conv2(y)\n",
        "    y = self.bn2(y)\n",
        "    y = self.add([self.bn3(self.shortcut(x)),y])\n",
        "    y = self.relu2(y)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEHDD12E16LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BottleneckBlock(Model):\n",
        "  \"\"\"Bottleneck Block with identity mapping in shortcuts (Option A).\"\"\"\n",
        "  def __init__(self, out_channels, stride=(1,1)):\n",
        "    super().__init__()\n",
        "    channel = out_channels//4\n",
        "    self.conv1 = Conv2D(channel, 1, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.relu1 = Activation('relu')\n",
        "    self.conv2 = Conv2D(channel, 3, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn2 = BatchNormalization()\n",
        "    self.relu2 = Activation('relu')\n",
        "    self.conv3 = Conv2D(out_channels, 1, strides=stride, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn3 = BatchNormalization()\n",
        "    if stride[0] != 1:\n",
        "      self.shortcut = Conv2D(out_channels, 1, strides=2, padding='same', kernel_regularizer=regularizers.l2(l=l))\n",
        "    else:\n",
        "      self.shortcut = Lambda(lambda x: x)\n",
        "    self.bn4 = BatchNormalization()\n",
        "    self.add = Add()\n",
        "    self.relu3 = Activation('relu')\n",
        "  \n",
        "  def call(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.bn1(y)\n",
        "    y = self.relu1(y)\n",
        "    y = self.conv2(y)\n",
        "    y = self.bn2(y)\n",
        "    y = self.relu2(y)\n",
        "    y = self.conv3(y)\n",
        "    y = self.bn3(y)\n",
        "    y = self.add([self.bn4(self.shortcut(x)),y])\n",
        "    y = self.relu3(y)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVEOnrOkFDp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(Model):\n",
        "  def _block(self, channel, n, block, stride=(1,1)):\n",
        "    layer_block = Sequential()\n",
        "    layer_block.add(block(channel, stride))\n",
        "    for i in range(n-1):\n",
        "      layer_block.add(block(channel))\n",
        "    return layer_block\n",
        "\n",
        "  def __init__(self, filters, n, block):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(filters[0], 3, padding='same', input_shape=(32,32,3), kernel_regularizer=regularizers.l2(l=l))\n",
        "    self.bn1 = BatchNormalization()\n",
        "    self.relu1 = Activation('relu')\n",
        "    self.block1 = self._block(filters[0], n, block, stride=(1,1))\n",
        "    self.block2 = self._block(filters[1], n, block, stride=(2,2))\n",
        "    self.block3 = self._block(filters[2], n, block, stride=(2,2))\n",
        "    self.pool = GlobalAveragePooling2D()\n",
        "    self.fc = Dense(256, activation='relu')\n",
        "    self.out = Dense(10, activation='softmax')\n",
        "  \n",
        "  def call(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.bn1(y)\n",
        "    y = self.relu1(y)\n",
        "    y = self.block1(y)\n",
        "    y = self.block2(y)\n",
        "    y = self.block3(y)\n",
        "    y = self.pool(y)\n",
        "    y = self.fc(y)\n",
        "    y = self.out(y)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgeaKfcXx2TG",
        "colab_type": "code",
        "outputId": "ca529782-24fe-4534-9714-4a7ef96b4b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images = train_images.astype('float32')\n",
        "test_labels = test_labels.astype('float32')\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_labels = utils.to_categorical(train_labels, 10)\n",
        "test_labels = utils.to_categorical(test_labels, 10)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(train_images)\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print(f'Train Set : {train_images.shape}',f'Test Set : {test_images.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set : (50000, 32, 32, 3) Test Set : (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmL_wy4Tx0Zp",
        "colab_type": "code",
        "outputId": "dbadfb18-607d-4069-ed80-5ca129a9fcd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "model1 = ResNet(filters=[16,32,64], n=5, block=BasicBlock)\n",
        "model1.build(input_shape=(None, 32, 32, 3))\n",
        "model1.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_357 (Conv2D)          multiple                  448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_489 (Bat multiple                  64        \n",
            "_________________________________________________________________\n",
            "activation_339 (Activation)  multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_27 (Sequential)   multiple                  24160     \n",
            "_________________________________________________________________\n",
            "sequential_28 (Sequential)   multiple                  90336     \n",
            "_________________________________________________________________\n",
            "sequential_29 (Sequential)   multiple                  356800    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_9 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             multiple                  16640     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             multiple                  2570      \n",
            "=================================================================\n",
            "Total params: 491,018\n",
            "Trainable params: 487,626\n",
            "Non-trainable params: 3,392\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e_w3a3wk5wV",
        "colab_type": "code",
        "outputId": "bca86dd7-b085-4dc2-f1a9-cb516ae3f2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model1.fit(train_images, train_labels, batch_size=128, epochs=100, validation_data=(test_images, test_labels))\n",
        "model1.fit(datagen.flow(train_images, train_labels, batch_size=128), \n",
        "           steps_per_epoch=train_images.shape[0]//128, epochs = 100, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 1.6732 - accuracy: 0.4267 - val_loss: 1.7973 - val_accuracy: 0.4098\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.2842 - accuracy: 0.5812 - val_loss: 1.7579 - val_accuracy: 0.4964\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.1091 - accuracy: 0.6497 - val_loss: 1.5882 - val_accuracy: 0.5193\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.9909 - accuracy: 0.6931 - val_loss: 1.6361 - val_accuracy: 0.5412\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.8944 - accuracy: 0.7294 - val_loss: 1.3572 - val_accuracy: 0.6319\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.8359 - accuracy: 0.7533 - val_loss: 0.9201 - val_accuracy: 0.7306\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.7836 - accuracy: 0.7728 - val_loss: 0.9746 - val_accuracy: 0.7216\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.7487 - accuracy: 0.7860 - val_loss: 1.0244 - val_accuracy: 0.6915\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.7154 - accuracy: 0.7988 - val_loss: 0.9378 - val_accuracy: 0.7356\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6955 - accuracy: 0.8054 - val_loss: 0.8430 - val_accuracy: 0.7674\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.6665 - accuracy: 0.8167 - val_loss: 0.8443 - val_accuracy: 0.7645\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6505 - accuracy: 0.8223 - val_loss: 0.9322 - val_accuracy: 0.7447\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.6394 - accuracy: 0.8277 - val_loss: 0.8197 - val_accuracy: 0.7744\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.6226 - accuracy: 0.8352 - val_loss: 0.8483 - val_accuracy: 0.7702\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.6015 - accuracy: 0.8420 - val_loss: 0.7846 - val_accuracy: 0.7912\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5860 - accuracy: 0.8476 - val_loss: 0.7925 - val_accuracy: 0.7934\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5870 - accuracy: 0.8484 - val_loss: 0.7510 - val_accuracy: 0.8039\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5705 - accuracy: 0.8535 - val_loss: 0.7528 - val_accuracy: 0.8057\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 0.5599 - accuracy: 0.8595 - val_loss: 0.6739 - val_accuracy: 0.8291\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5552 - accuracy: 0.8601 - val_loss: 0.7713 - val_accuracy: 0.8007\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.5469 - accuracy: 0.8640 - val_loss: 0.9324 - val_accuracy: 0.7635\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5420 - accuracy: 0.8674 - val_loss: 0.6919 - val_accuracy: 0.8204\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5301 - accuracy: 0.8698 - val_loss: 0.7121 - val_accuracy: 0.8212\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5229 - accuracy: 0.8749 - val_loss: 0.8284 - val_accuracy: 0.7939\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5217 - accuracy: 0.8751 - val_loss: 0.6194 - val_accuracy: 0.8453\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5122 - accuracy: 0.8765 - val_loss: 0.6687 - val_accuracy: 0.8287\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5079 - accuracy: 0.8781 - val_loss: 0.7804 - val_accuracy: 0.8039\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4989 - accuracy: 0.8848 - val_loss: 0.8916 - val_accuracy: 0.7851\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4993 - accuracy: 0.8832 - val_loss: 0.6742 - val_accuracy: 0.8276\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4915 - accuracy: 0.8858 - val_loss: 0.6162 - val_accuracy: 0.8484\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4862 - accuracy: 0.8886 - val_loss: 0.7685 - val_accuracy: 0.8099\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4844 - accuracy: 0.8879 - val_loss: 0.6683 - val_accuracy: 0.8300\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4822 - accuracy: 0.8898 - val_loss: 0.6217 - val_accuracy: 0.8477\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4785 - accuracy: 0.8906 - val_loss: 0.5650 - val_accuracy: 0.8643\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4734 - accuracy: 0.8909 - val_loss: 0.5751 - val_accuracy: 0.8625\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4761 - accuracy: 0.8924 - val_loss: 0.6195 - val_accuracy: 0.8521\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4692 - accuracy: 0.8932 - val_loss: 0.8052 - val_accuracy: 0.8073\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4632 - accuracy: 0.8961 - val_loss: 0.6288 - val_accuracy: 0.8510\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4579 - accuracy: 0.8983 - val_loss: 0.6401 - val_accuracy: 0.8425\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4574 - accuracy: 0.8984 - val_loss: 0.6270 - val_accuracy: 0.8491\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4587 - accuracy: 0.9004 - val_loss: 0.6740 - val_accuracy: 0.8367\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4564 - accuracy: 0.9012 - val_loss: 0.7853 - val_accuracy: 0.8043\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4513 - accuracy: 0.9012 - val_loss: 0.6153 - val_accuracy: 0.8522\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 29s 76ms/step - loss: 0.4433 - accuracy: 0.9038 - val_loss: 0.7174 - val_accuracy: 0.8281\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 0.4414 - accuracy: 0.9033 - val_loss: 0.7214 - val_accuracy: 0.8247\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 0.4449 - accuracy: 0.9033 - val_loss: 0.6094 - val_accuracy: 0.8578\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 31s 80ms/step - loss: 0.4409 - accuracy: 0.9044 - val_loss: 0.9860 - val_accuracy: 0.7764\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 32s 83ms/step - loss: 0.4359 - accuracy: 0.9062 - val_loss: 0.6069 - val_accuracy: 0.8623\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 32s 81ms/step - loss: 0.4340 - accuracy: 0.9070 - val_loss: 0.8539 - val_accuracy: 0.7973\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.4338 - accuracy: 0.9077 - val_loss: 0.5785 - val_accuracy: 0.8678\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4338 - accuracy: 0.9073 - val_loss: 0.5338 - val_accuracy: 0.8759\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4287 - accuracy: 0.9093 - val_loss: 0.5943 - val_accuracy: 0.8637\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4229 - accuracy: 0.9121 - val_loss: 0.6014 - val_accuracy: 0.8640\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4296 - accuracy: 0.9082 - val_loss: 0.5697 - val_accuracy: 0.8691\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4252 - accuracy: 0.9103 - val_loss: 0.6186 - val_accuracy: 0.8595\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4227 - accuracy: 0.9120 - val_loss: 0.5668 - val_accuracy: 0.8705\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4150 - accuracy: 0.9150 - val_loss: 0.7455 - val_accuracy: 0.8294\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4169 - accuracy: 0.9150 - val_loss: 0.6315 - val_accuracy: 0.8555\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4134 - accuracy: 0.9160 - val_loss: 0.7699 - val_accuracy: 0.8300\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4173 - accuracy: 0.9126 - val_loss: 0.6079 - val_accuracy: 0.8641\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4143 - accuracy: 0.9154 - val_loss: 0.8437 - val_accuracy: 0.8081\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4129 - accuracy: 0.9156 - val_loss: 0.7444 - val_accuracy: 0.8345\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4075 - accuracy: 0.9167 - val_loss: 0.6702 - val_accuracy: 0.8469\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4044 - accuracy: 0.9164 - val_loss: 0.6416 - val_accuracy: 0.8570\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4022 - accuracy: 0.9192 - val_loss: 0.5154 - val_accuracy: 0.8888\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4099 - accuracy: 0.9160 - val_loss: 0.6972 - val_accuracy: 0.8429\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.4056 - accuracy: 0.9164 - val_loss: 0.6320 - val_accuracy: 0.8592\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4031 - accuracy: 0.9178 - val_loss: 0.7003 - val_accuracy: 0.8381\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3985 - accuracy: 0.9203 - val_loss: 0.7694 - val_accuracy: 0.8216\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4010 - accuracy: 0.9192 - val_loss: 0.5955 - val_accuracy: 0.8604\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3968 - accuracy: 0.9204 - val_loss: 0.6607 - val_accuracy: 0.8529\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3922 - accuracy: 0.9220 - val_loss: 0.5303 - val_accuracy: 0.8820\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3964 - accuracy: 0.9211 - val_loss: 0.6961 - val_accuracy: 0.8388\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3954 - accuracy: 0.9203 - val_loss: 0.6905 - val_accuracy: 0.8443\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3982 - accuracy: 0.9193 - val_loss: 0.7013 - val_accuracy: 0.8439\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3925 - accuracy: 0.9219 - val_loss: 0.7208 - val_accuracy: 0.8403\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3880 - accuracy: 0.9227 - val_loss: 0.6646 - val_accuracy: 0.8520\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3901 - accuracy: 0.9217 - val_loss: 0.5624 - val_accuracy: 0.8738\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3871 - accuracy: 0.9232 - val_loss: 0.6494 - val_accuracy: 0.8526\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3876 - accuracy: 0.9234 - val_loss: 0.8157 - val_accuracy: 0.8195\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3850 - accuracy: 0.9246 - val_loss: 0.5813 - val_accuracy: 0.8703\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3868 - accuracy: 0.9230 - val_loss: 0.5738 - val_accuracy: 0.8727\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3843 - accuracy: 0.9251 - val_loss: 0.8513 - val_accuracy: 0.8091\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3843 - accuracy: 0.9255 - val_loss: 0.7565 - val_accuracy: 0.8301\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3824 - accuracy: 0.9259 - val_loss: 0.7007 - val_accuracy: 0.8429\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3813 - accuracy: 0.9254 - val_loss: 0.6740 - val_accuracy: 0.8491\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3792 - accuracy: 0.9265 - val_loss: 0.6548 - val_accuracy: 0.8546\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3828 - accuracy: 0.9262 - val_loss: 0.5527 - val_accuracy: 0.8769\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3779 - accuracy: 0.9270 - val_loss: 0.5903 - val_accuracy: 0.8725\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3762 - accuracy: 0.9282 - val_loss: 0.7264 - val_accuracy: 0.8387\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3763 - accuracy: 0.9268 - val_loss: 0.6024 - val_accuracy: 0.8698\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3754 - accuracy: 0.9273 - val_loss: 0.8515 - val_accuracy: 0.8144\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3762 - accuracy: 0.9269 - val_loss: 0.8332 - val_accuracy: 0.8157\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.3739 - accuracy: 0.9287 - val_loss: 0.6761 - val_accuracy: 0.8502\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 32s 82ms/step - loss: 0.3692 - accuracy: 0.9298 - val_loss: 0.6886 - val_accuracy: 0.8485\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3706 - accuracy: 0.9291 - val_loss: 0.5837 - val_accuracy: 0.8735\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3781 - accuracy: 0.9251 - val_loss: 0.5709 - val_accuracy: 0.8712\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.3722 - accuracy: 0.9299 - val_loss: 0.6446 - val_accuracy: 0.8627\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3693 - accuracy: 0.9308 - val_loss: 0.5842 - val_accuracy: 0.8692\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.3749 - accuracy: 0.9293 - val_loss: 0.6040 - val_accuracy: 0.8673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f027f0f7b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-MQcVwju8ql",
        "colab_type": "code",
        "outputId": "922f70ea-592f-4286-d3f5-d69beddfe77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "model2 = ResNet(filters=[16,32,64], n=10, block=BottleneckBlock)\n",
        "model2.build(input_shape=(None, 32, 32, 3))\n",
        "model2.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_390 (Conv2D)          multiple                  448       \n",
            "_________________________________________________________________\n",
            "batch_normalization_535 (Bat multiple                  64        \n",
            "_________________________________________________________________\n",
            "activation_370 (Activation)  multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_30 (Sequential)   multiple                  4560      \n",
            "_________________________________________________________________\n",
            "sequential_31 (Sequential)   multiple                  14976     \n",
            "_________________________________________________________________\n",
            "sequential_32 (Sequential)   multiple                  52480     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             multiple                  16640     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             multiple                  2570      \n",
            "=================================================================\n",
            "Total params: 91,738\n",
            "Trainable params: 86,106\n",
            "Non-trainable params: 5,632\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ipcq3Hu_V-",
        "colab_type": "code",
        "outputId": "76be033e-a803-4152-de2d-a109513cac7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model2.fit(train_images, train_labels, batch_size=128, epochs=100, validation_data=(test_images, test_labels))\n",
        "model2.fit(datagen.flow(train_images, train_labels, batch_size=128), \n",
        "           steps_per_epoch=train_images.shape[0]//128, epochs = 100, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 39s 100ms/step - loss: 2.2391 - accuracy: 0.2076 - val_loss: 2.9519 - val_accuracy: 0.1118\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 2.0463 - accuracy: 0.2900 - val_loss: 2.0557 - val_accuracy: 0.2848\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.8587 - accuracy: 0.3626 - val_loss: 1.9168 - val_accuracy: 0.3502\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.7536 - accuracy: 0.4005 - val_loss: 1.7585 - val_accuracy: 0.3926\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.6780 - accuracy: 0.4300 - val_loss: 1.7788 - val_accuracy: 0.3927\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 1.6087 - accuracy: 0.4525 - val_loss: 1.6037 - val_accuracy: 0.4532\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5565 - accuracy: 0.4714 - val_loss: 1.6800 - val_accuracy: 0.4384\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5014 - accuracy: 0.4925 - val_loss: 1.5496 - val_accuracy: 0.4776\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4439 - accuracy: 0.5122 - val_loss: 1.7728 - val_accuracy: 0.4190\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 1.4027 - accuracy: 0.5263 - val_loss: 1.3752 - val_accuracy: 0.5375\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.3502 - accuracy: 0.5494 - val_loss: 1.7216 - val_accuracy: 0.4627\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 1.3112 - accuracy: 0.5638 - val_loss: 1.4522 - val_accuracy: 0.5206\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.2782 - accuracy: 0.5787 - val_loss: 1.5254 - val_accuracy: 0.5108\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.2367 - accuracy: 0.5932 - val_loss: 1.5639 - val_accuracy: 0.5298\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 1.1932 - accuracy: 0.6095 - val_loss: 1.2347 - val_accuracy: 0.6013\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 1.1671 - accuracy: 0.6205 - val_loss: 1.3055 - val_accuracy: 0.5802\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.1445 - accuracy: 0.6277 - val_loss: 1.3596 - val_accuracy: 0.5735\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 1.1091 - accuracy: 0.6393 - val_loss: 1.2518 - val_accuracy: 0.5983\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 1.0846 - accuracy: 0.6482 - val_loss: 1.2535 - val_accuracy: 0.5962\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 1.0600 - accuracy: 0.6571 - val_loss: 1.2096 - val_accuracy: 0.6167\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 1.0388 - accuracy: 0.6661 - val_loss: 1.6056 - val_accuracy: 0.5404\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 1.0110 - accuracy: 0.6766 - val_loss: 1.2691 - val_accuracy: 0.5967\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.9920 - accuracy: 0.6806 - val_loss: 1.2342 - val_accuracy: 0.6147\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.9766 - accuracy: 0.6866 - val_loss: 1.2400 - val_accuracy: 0.6222\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.9542 - accuracy: 0.6972 - val_loss: 1.4316 - val_accuracy: 0.5828\n",
            "Epoch 26/100\n",
            "200/390 [==============>...............] - ETA: 15s - loss: 0.9472 - accuracy: 0.6953"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b4c3e1b7c08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model2.fit(datagen.flow(train_images, train_labels, batch_size=128), \n\u001b[0;32m----> 2\u001b[0;31m            steps_per_epoch=train_images.shape[0]//128, epochs = 100, validation_data=(test_images, test_labels))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqHo-gkMEenJ",
        "colab_type": "code",
        "outputId": "237a2937-941a-417e-dfb5-30850e17c999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "source": [
        "l = 5*1e-5\n",
        "model2.fit(datagen.flow(train_images, train_labels, batch_size=128), \n",
        "           steps_per_epoch=train_images.shape[0]//128, epochs = 50, initial_epoch=26, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/50\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 0.9251 - accuracy: 0.7051 - val_loss: 1.1973 - val_accuracy: 0.6386\n",
            "Epoch 28/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.9066 - accuracy: 0.7107 - val_loss: 1.1325 - val_accuracy: 0.6528\n",
            "Epoch 29/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8903 - accuracy: 0.7179 - val_loss: 1.2638 - val_accuracy: 0.6264\n",
            "Epoch 30/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8726 - accuracy: 0.7238 - val_loss: 1.2020 - val_accuracy: 0.6403\n",
            "Epoch 31/50\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.8586 - accuracy: 0.7301 - val_loss: 1.0575 - val_accuracy: 0.6816\n",
            "Epoch 32/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8379 - accuracy: 0.7372 - val_loss: 1.0261 - val_accuracy: 0.6836\n",
            "Epoch 33/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.8265 - accuracy: 0.7423 - val_loss: 0.9701 - val_accuracy: 0.7001\n",
            "Epoch 34/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8134 - accuracy: 0.7441 - val_loss: 1.0504 - val_accuracy: 0.6787\n",
            "Epoch 35/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.7991 - accuracy: 0.7501 - val_loss: 1.0762 - val_accuracy: 0.6796\n",
            "Epoch 36/50\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.7859 - accuracy: 0.7549 - val_loss: 0.9872 - val_accuracy: 0.6958\n",
            "Epoch 37/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.7723 - accuracy: 0.7597 - val_loss: 1.0798 - val_accuracy: 0.6836\n",
            "Epoch 38/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.7573 - accuracy: 0.7643 - val_loss: 1.1615 - val_accuracy: 0.6440\n",
            "Epoch 39/50\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 0.7464 - accuracy: 0.7698 - val_loss: 1.0842 - val_accuracy: 0.6858\n",
            "Epoch 40/50\n",
            "390/390 [==============================] - 35s 91ms/step - loss: 0.7391 - accuracy: 0.7715 - val_loss: 0.8530 - val_accuracy: 0.7449\n",
            "Epoch 41/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.7267 - accuracy: 0.7775 - val_loss: 0.9412 - val_accuracy: 0.7231\n",
            "Epoch 42/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.7179 - accuracy: 0.7791 - val_loss: 0.9675 - val_accuracy: 0.7191\n",
            "Epoch 43/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.7072 - accuracy: 0.7824 - val_loss: 1.3067 - val_accuracy: 0.6323\n",
            "Epoch 44/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6995 - accuracy: 0.7878 - val_loss: 1.0670 - val_accuracy: 0.6984\n",
            "Epoch 45/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6919 - accuracy: 0.7891 - val_loss: 1.0032 - val_accuracy: 0.7134\n",
            "Epoch 46/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6817 - accuracy: 0.7914 - val_loss: 1.0262 - val_accuracy: 0.6925\n",
            "Epoch 47/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6780 - accuracy: 0.7958 - val_loss: 0.7419 - val_accuracy: 0.7735\n",
            "Epoch 48/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6659 - accuracy: 0.7972 - val_loss: 0.8892 - val_accuracy: 0.7407\n",
            "Epoch 49/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6595 - accuracy: 0.8009 - val_loss: 0.9677 - val_accuracy: 0.7261\n",
            "Epoch 50/50\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.6615 - accuracy: 0.8006 - val_loss: 0.7788 - val_accuracy: 0.7619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f01b3109ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s35bHuo7emr3",
        "colab_type": "code",
        "outputId": "8ec0c9d0-cfb5-4c9f-affe-e53b67082f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2.fit(datagen.flow(train_images, train_labels, batch_size=128), \n",
        "           steps_per_epoch=train_images.shape[0]//128, epochs = 100, initial_epoch=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 51/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.6514 - accuracy: 0.8024 - val_loss: 0.7072 - val_accuracy: 0.7859\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.6451 - accuracy: 0.8042 - val_loss: 0.7288 - val_accuracy: 0.7852\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.6382 - accuracy: 0.8102 - val_loss: 0.7332 - val_accuracy: 0.7794\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.6308 - accuracy: 0.8102 - val_loss: 0.9604 - val_accuracy: 0.7259\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.6298 - accuracy: 0.8111 - val_loss: 0.7061 - val_accuracy: 0.7944\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.6159 - accuracy: 0.8149 - val_loss: 0.7210 - val_accuracy: 0.7853\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.6155 - accuracy: 0.8165 - val_loss: 0.7731 - val_accuracy: 0.7797\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.6170 - accuracy: 0.8148 - val_loss: 0.8865 - val_accuracy: 0.7455\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 37s 94ms/step - loss: 0.6038 - accuracy: 0.8202 - val_loss: 0.9553 - val_accuracy: 0.7266\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 38s 96ms/step - loss: 0.5975 - accuracy: 0.8221 - val_loss: 0.8664 - val_accuracy: 0.7497\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 36s 93ms/step - loss: 0.6004 - accuracy: 0.8198 - val_loss: 1.0277 - val_accuracy: 0.7179\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.5939 - accuracy: 0.8220 - val_loss: 0.9316 - val_accuracy: 0.7276\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 36s 92ms/step - loss: 0.5936 - accuracy: 0.8229 - val_loss: 0.7999 - val_accuracy: 0.7686\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.5807 - accuracy: 0.8275 - val_loss: 0.7014 - val_accuracy: 0.7916\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 36s 91ms/step - loss: 0.5830 - accuracy: 0.8269 - val_loss: 0.6890 - val_accuracy: 0.8032\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5752 - accuracy: 0.8298 - val_loss: 0.7910 - val_accuracy: 0.7734\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5752 - accuracy: 0.8296 - val_loss: 0.7913 - val_accuracy: 0.7772\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5718 - accuracy: 0.8317 - val_loss: 0.7605 - val_accuracy: 0.7797\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5688 - accuracy: 0.8336 - val_loss: 0.6837 - val_accuracy: 0.8030\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5623 - accuracy: 0.8352 - val_loss: 0.6954 - val_accuracy: 0.7995\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5619 - accuracy: 0.8326 - val_loss: 0.6410 - val_accuracy: 0.8175\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5558 - accuracy: 0.8373 - val_loss: 0.7446 - val_accuracy: 0.7889\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5500 - accuracy: 0.8366 - val_loss: 0.9091 - val_accuracy: 0.7509\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5491 - accuracy: 0.8397 - val_loss: 0.7039 - val_accuracy: 0.8019\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5486 - accuracy: 0.8393 - val_loss: 1.0830 - val_accuracy: 0.7186\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5467 - accuracy: 0.8393 - val_loss: 0.7870 - val_accuracy: 0.7789\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5437 - accuracy: 0.8410 - val_loss: 0.6720 - val_accuracy: 0.8116\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5344 - accuracy: 0.8440 - val_loss: 0.6685 - val_accuracy: 0.8072\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 35s 90ms/step - loss: 0.5339 - accuracy: 0.8444 - val_loss: 0.7740 - val_accuracy: 0.7838\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5270 - accuracy: 0.8467 - val_loss: 0.6967 - val_accuracy: 0.8052\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5282 - accuracy: 0.8461 - val_loss: 0.7439 - val_accuracy: 0.7947\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5235 - accuracy: 0.8462 - val_loss: 0.8354 - val_accuracy: 0.7677\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5195 - accuracy: 0.8483 - val_loss: 0.6896 - val_accuracy: 0.8088\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5209 - accuracy: 0.8499 - val_loss: 0.6910 - val_accuracy: 0.8046\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5166 - accuracy: 0.8504 - val_loss: 0.7902 - val_accuracy: 0.7873\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5096 - accuracy: 0.8539 - val_loss: 0.7180 - val_accuracy: 0.7978\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5133 - accuracy: 0.8524 - val_loss: 0.7406 - val_accuracy: 0.7828\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5137 - accuracy: 0.8522 - val_loss: 0.6235 - val_accuracy: 0.8246\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5071 - accuracy: 0.8529 - val_loss: 0.7833 - val_accuracy: 0.7826\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.5039 - accuracy: 0.8545 - val_loss: 0.7432 - val_accuracy: 0.7935\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.5017 - accuracy: 0.8549 - val_loss: 0.7214 - val_accuracy: 0.8057\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.4985 - accuracy: 0.8557 - val_loss: 0.7674 - val_accuracy: 0.7940\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.4992 - accuracy: 0.8568 - val_loss: 0.9411 - val_accuracy: 0.7587\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.4952 - accuracy: 0.8576 - val_loss: 0.7058 - val_accuracy: 0.8077\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.4937 - accuracy: 0.8598 - val_loss: 0.7249 - val_accuracy: 0.7975\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.4950 - accuracy: 0.8580 - val_loss: 0.6739 - val_accuracy: 0.8083\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.4827 - accuracy: 0.8630 - val_loss: 1.1116 - val_accuracy: 0.7208\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.4905 - accuracy: 0.8597 - val_loss: 0.8095 - val_accuracy: 0.7834\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 35s 89ms/step - loss: 0.4905 - accuracy: 0.8573 - val_loss: 0.7530 - val_accuracy: 0.7940\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 34s 88ms/step - loss: 0.4803 - accuracy: 0.8646 - val_loss: 0.6963 - val_accuracy: 0.8012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f01906e3630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrg9pixhJ5GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}